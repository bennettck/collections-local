# Retrieval Evaluation Report (Multi-Search Comparison)

**Run ID**: eval_20251222_073056
**Timestamp**: 2025-12-22T07:30:56.873530+00:00
**API Endpoint**: http://localhost:8000
**Dataset**: retrieval_evaluation_dataset.json (50 queries)
**Search Types**: bm25, vector, bm25-lc, vector-lc, hybrid-lc
**Parallel Execution**: Yes
**Target Items**: 55 | **Actual Items**: 55 ✓

---

## Performance Comparison

| Search Type | Avg Time (ms) | Min (ms) | Max (ms) |
|-------------|---------------|----------|----------|
| **bm25** | 2.2 | 0.7 | 6.6 |
| **vector** | 96.7 | 81.5 | 359.5 |
| **bm25-lc** | 13.5 | 3.3 | 36.6 |
| **vector-lc** | 105.7 | 93.5 | 197.0 |
| **hybrid-lc** | 131.5 | 109.0 | 177.7 |

---

## Summary Metrics Comparison

### Precision

| Metric | **bm25** | **vector** | **bm25-lc** | **vector-lc** | **hybrid-lc** | Δ (abs) | Δ (%) | Winner |
|--------|------|------|------|------|------|---------|-------|--------|
| **@1** | 0.881 | 0.976 | 0.881 | 0.976 | 0.905 | - | - | - |
| **@3** | 0.508 | 0.595 | 0.508 | 0.595 | 0.603 | - | - | - |
| **@5** | 0.376 | 0.414 | 0.376 | 0.414 | 0.400 | - | - | - |
| **@10** | 0.207 | 0.226 | 0.207 | 0.226 | 0.226 | - | - | - |


### Recall

| Metric | **bm25** | **vector** | **bm25-lc** | **vector-lc** | **hybrid-lc** | Δ (abs) | Δ (%) | Winner |
|--------|------|------|------|------|------|---------|-------|--------|
| **@1** | 0.546 | 0.578 | 0.546 | 0.578 | 0.551 | - | - | - |
| **@3** | 0.749 | 0.833 | 0.749 | 0.833 | 0.834 | - | - | - |
| **@5** | 0.846 | 0.901 | 0.846 | 0.901 | 0.880 | - | - | - |
| **@10** | 0.885 | 0.942 | 0.885 | 0.942 | 0.942 | - | - | - |


### NDCG

| Metric | **bm25** | **vector** | **bm25-lc** | **vector-lc** | **hybrid-lc** | Δ (abs) | Δ (%) | Winner |
|--------|------|------|------|------|------|---------|-------|--------|
| **@1** | 0.865 | 0.976 | 0.865 | 0.976 | 0.905 | - | - | - |
| **@3** | 0.799 | 0.900 | 0.799 | 0.900 | 0.903 | - | - | - |
| **@5** | 0.836 | 0.910 | 0.836 | 0.910 | 0.892 | - | - | - |
| **@10** | 0.859 | 0.934 | 0.859 | 0.934 | 0.927 | - | - | - |


### Mean Reciprocal Rank (MRR)

| Search Type | MRR | Δ vs first | Winner |
|-------------|-----|------------|--------|
| **bm25** | 0.902 | - |  |
| **vector** | 0.979 | - |  |
| **bm25-lc** | 0.902 | - |  |
| **vector-lc** | 0.979 | - |  |
| **hybrid-lc** | 0.937 | - |  |

---

## By Query Type Comparison

### multi-item-recall

| Metric | **bm25** | **vector** | **bm25-lc** | **vector-lc** | **hybrid-lc** | Winner |
|--------|------|------|------|------|------|--------|
| P@5 | 0.59 | 0.63 | 0.59 | 0.63 | 0.61 | VECTOR |
| R@5 | 0.86 | 0.91 | 0.86 | 0.91 | 0.89 | VECTOR |
| MRR | 0.90 | 1.00 | 0.90 | 1.00 | 0.97 | VECTOR |


### semantic

| Metric | **bm25** | **vector** | **bm25-lc** | **vector-lc** | **hybrid-lc** | Winner |
|--------|------|------|------|------|------|--------|
| P@5 | 0.33 | 0.42 | 0.33 | 0.42 | 0.38 | VECTOR |
| R@5 | 0.64 | 0.76 | 0.64 | 0.76 | 0.72 | VECTOR |
| MRR | 0.78 | 0.93 | 0.78 | 0.93 | 0.82 | VECTOR |


### single-item-precision

| Metric | **bm25** | **vector** | **bm25-lc** | **vector-lc** | **hybrid-lc** | Winner |
|--------|------|------|------|------|------|--------|
| P@5 | 0.20 | 0.20 | 0.20 | 0.20 | 0.20 | BM25 |
| R@5 | 1.00 | 1.00 | 1.00 | 1.00 | 1.00 | BM25 |
| MRR | 1.00 | 1.00 | 1.00 | 1.00 | 1.00 | BM25 |

