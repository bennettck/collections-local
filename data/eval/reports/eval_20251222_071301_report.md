# Retrieval Evaluation Report (Multi-Search Comparison)

**Run ID**: eval_20251222_071301
**Timestamp**: 2025-12-22T07:13:01.333970+00:00
**API Endpoint**: http://localhost:8000
**Dataset**: retrieval_evaluation_dataset.json (50 queries)
**Search Types**: bm25, vector, bm25-lc, vector-lc, hybrid-lc
**Parallel Execution**: Yes
**Target Items**: 55 | **Actual Items**: 55 ✓

---

## Performance Comparison

| Search Type | Avg Time (ms) | Min (ms) | Max (ms) |
|-------------|---------------|----------|----------|
| **bm25** | 2.3 | 0.8 | 9.6 |
| **vector** | 91.8 | 81.2 | 268.0 |
| **bm25-lc** | 12.0 | 1.9 | 31.9 |
| **vector-lc** | 101.1 | 92.5 | 136.1 |
| **hybrid-lc** | 133.2 | 108.9 | 261.4 |

---

## Summary Metrics Comparison

### Precision

| Metric | **bm25** | **vector** | **bm25-lc** | **vector-lc** | **hybrid-lc** | Δ (abs) | Δ (%) | Winner |
|--------|------|------|------|------|------|---------|-------|--------|
| **@1** | 0.881 | 0.976 | 0.881 | 0.976 | 0.905 | - | - | - |
| **@3** | 0.508 | 0.595 | 0.508 | 0.595 | 0.587 | - | - | - |
| **@5** | 0.376 | 0.414 | 0.376 | 0.414 | 0.386 | - | - | - |
| **@10** | 0.207 | 0.226 | 0.207 | 0.226 | 0.224 | - | - | - |


### Recall

| Metric | **bm25** | **vector** | **bm25-lc** | **vector-lc** | **hybrid-lc** | Δ (abs) | Δ (%) | Winner |
|--------|------|------|------|------|------|---------|-------|--------|
| **@1** | 0.546 | 0.578 | 0.546 | 0.578 | 0.551 | - | - | - |
| **@3** | 0.749 | 0.833 | 0.749 | 0.833 | 0.819 | - | - | - |
| **@5** | 0.846 | 0.901 | 0.846 | 0.901 | 0.856 | - | - | - |
| **@10** | 0.885 | 0.942 | 0.885 | 0.942 | 0.936 | - | - | - |


### NDCG

| Metric | **bm25** | **vector** | **bm25-lc** | **vector-lc** | **hybrid-lc** | Δ (abs) | Δ (%) | Winner |
|--------|------|------|------|------|------|---------|-------|--------|
| **@1** | 0.865 | 0.976 | 0.865 | 0.976 | 0.889 | - | - | - |
| **@3** | 0.799 | 0.900 | 0.799 | 0.900 | 0.885 | - | - | - |
| **@5** | 0.836 | 0.910 | 0.836 | 0.910 | 0.868 | - | - | - |
| **@10** | 0.859 | 0.934 | 0.859 | 0.934 | 0.917 | - | - | - |


### Mean Reciprocal Rank (MRR)

| Search Type | MRR | Δ vs first | Winner |
|-------------|-----|------------|--------|
| **bm25** | 0.902 | - |  |
| **vector** | 0.979 | - |  |
| **bm25-lc** | 0.902 | - |  |
| **vector-lc** | 0.979 | - |  |
| **hybrid-lc** | 0.925 | - |  |

---

## By Query Type Comparison

### multi-item-recall

| Metric | **bm25** | **vector** | **bm25-lc** | **vector-lc** | **hybrid-lc** | Winner |
|--------|------|------|------|------|------|--------|
| P@5 | 0.59 | 0.63 | 0.59 | 0.63 | 0.61 | VECTOR |
| R@5 | 0.86 | 0.91 | 0.86 | 0.91 | 0.89 | VECTOR |
| MRR | 0.90 | 1.00 | 0.90 | 1.00 | 0.97 | VECTOR |


### semantic

| Metric | **bm25** | **vector** | **bm25-lc** | **vector-lc** | **hybrid-lc** | Winner |
|--------|------|------|------|------|------|--------|
| P@5 | 0.33 | 0.42 | 0.33 | 0.42 | 0.33 | VECTOR |
| R@5 | 0.64 | 0.76 | 0.64 | 0.76 | 0.63 | VECTOR |
| MRR | 0.78 | 0.93 | 0.78 | 0.93 | 0.78 | VECTOR |


### single-item-precision

| Metric | **bm25** | **vector** | **bm25-lc** | **vector-lc** | **hybrid-lc** | Winner |
|--------|------|------|------|------|------|--------|
| P@5 | 0.20 | 0.20 | 0.20 | 0.20 | 0.20 | BM25 |
| R@5 | 1.00 | 1.00 | 1.00 | 1.00 | 1.00 | BM25 |
| MRR | 1.00 | 1.00 | 1.00 | 1.00 | 1.00 | BM25 |

